{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN02_wordComplete.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeonJeongMin/tensorflow-examples/blob/master/Supervised%20Learning/RNN02_wordComplete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fF-zcMcOK_6k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Import module"
      ]
    },
    {
      "metadata": {
        "id": "ZwzHUt6y4lnr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "char_arr = ['a','b','c','d','e','f','g',\n",
        "            'h','i','j','k','l','m','n',\n",
        "            'o','p','q','r','s','t','u',\n",
        "            'v','w','x','y','z']\n",
        "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
        "dic_len = len(num_dic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GL4k7t2lLHN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Make a word\n"
      ]
    },
    {
      "metadata": {
        "id": "ElYlJ52s6wVO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq_data = ['abcd','word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
        "def make_batch(seq_data):\n",
        "  input_batch=[]\n",
        "  target_batch=[]\n",
        "  \n",
        "  for seq in seq_data:\n",
        "    input = [num_dic[n] for n in seq[:-1]]\n",
        "    target = num_dic[seq[-1]]\n",
        "    input_batch.append(np.eye(dic_len)[input])#one_hot_encoding\n",
        "    target_batch.append(target)\n",
        "    \n",
        "  return input_batch, target_batch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GxIY0kjYLYEp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Setting Parameter"
      ]
    },
    {
      "metadata": {
        "id": "C_2DsPbTEPuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "n_hidden =128\n",
        "total_epoch = 50\n",
        "\n",
        "n_step = 3\n",
        "n_input = n_class = dic_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QFMV-lALdXr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Make a Multi-RNN network"
      ]
    },
    {
      "metadata": {
        "id": "iYF2GyOhFGhQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
        "Y = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "cell1 = tf.nn.rnn_cell.LSTMCell(n_hidden)\n",
        "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob = 0.5)\n",
        "cell2 = tf.nn.rnn_cell.LSTMCell(n_hidden)\n",
        "\n",
        "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1,cell2])\n",
        "\n",
        "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
        "\n",
        "outputs = tf.transpose(outputs,[1,0,2])\n",
        "outputs = outputs[-1]\n",
        "model = tf.layers.dense(outputs, n_class, activation = None)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                        logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FzKwHXdNLh2R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Learning"
      ]
    },
    {
      "metadata": {
        "id": "zb3-suBAGIlU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "81b473d2-d77b-4850-c2a6-e09f85f068fd"
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "input_batch, target_batch = make_batch(seq_data)\n",
        "\n",
        "print('Learning Start!')\n",
        "\n",
        "for epoch in range(total_epoch):\n",
        "  _, cost_val = sess.run([optimizer,cost], feed_dict={X:input_batch, Y:target_batch})\n",
        "  print('Epoch:{:02d}'.format(epoch+1), 'Cost:%3f'%cost_val)\n",
        "  \n",
        "print('Learning Finish!')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning Start!\n",
            "Epoch:01 Cost:3.264422\n",
            "Epoch:02 Cost:3.126595\n",
            "Epoch:03 Cost:2.892318\n",
            "Epoch:04 Cost:2.328626\n",
            "Epoch:05 Cost:1.563359\n",
            "Epoch:06 Cost:1.695839\n",
            "Epoch:07 Cost:1.341806\n",
            "Epoch:08 Cost:1.002718\n",
            "Epoch:09 Cost:1.083760\n",
            "Epoch:10 Cost:0.993529\n",
            "Epoch:11 Cost:0.795121\n",
            "Epoch:12 Cost:0.641947\n",
            "Epoch:13 Cost:0.540534\n",
            "Epoch:14 Cost:0.514443\n",
            "Epoch:15 Cost:0.409392\n",
            "Epoch:16 Cost:0.351125\n",
            "Epoch:17 Cost:0.332804\n",
            "Epoch:18 Cost:0.262500\n",
            "Epoch:19 Cost:0.369718\n",
            "Epoch:20 Cost:0.292628\n",
            "Epoch:21 Cost:0.311017\n",
            "Epoch:22 Cost:0.215484\n",
            "Epoch:23 Cost:0.187132\n",
            "Epoch:24 Cost:0.231440\n",
            "Epoch:25 Cost:0.211865\n",
            "Epoch:26 Cost:0.158947\n",
            "Epoch:27 Cost:0.154033\n",
            "Epoch:28 Cost:0.260898\n",
            "Epoch:29 Cost:0.252150\n",
            "Epoch:30 Cost:0.103076\n",
            "Epoch:31 Cost:0.121701\n",
            "Epoch:32 Cost:0.110077\n",
            "Epoch:33 Cost:0.141599\n",
            "Epoch:34 Cost:0.126803\n",
            "Epoch:35 Cost:0.108686\n",
            "Epoch:36 Cost:0.175021\n",
            "Epoch:37 Cost:0.106488\n",
            "Epoch:38 Cost:0.210099\n",
            "Epoch:39 Cost:0.133590\n",
            "Epoch:40 Cost:0.085403\n",
            "Epoch:41 Cost:0.097421\n",
            "Epoch:42 Cost:0.041355\n",
            "Epoch:43 Cost:0.129765\n",
            "Epoch:44 Cost:0.068772\n",
            "Epoch:45 Cost:0.060420\n",
            "Epoch:46 Cost:0.050909\n",
            "Epoch:47 Cost:0.065368\n",
            "Epoch:48 Cost:0.084995\n",
            "Epoch:49 Cost:0.033254\n",
            "Epoch:50 Cost:0.020806\n",
            "Learning Finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3WS19O95Ljrr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Check Accuracy"
      ]
    },
    {
      "metadata": {
        "id": "_X_dQ7GkG6Br",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "24cbb9f2-6604-46b6-81f2-0a141418ccce"
      },
      "cell_type": "code",
      "source": [
        "prediction = tf.cast(tf.argmax(model,1),tf.int32)\n",
        "prediction_check = tf.equal(prediction,Y)\n",
        "accuracy = tf.reduce_mean(tf.cast(prediction_check,tf.float32))\n",
        "\n",
        "input_batch, target_batch = make_batch(seq_data)\n",
        "\n",
        "predict, accuracy_val = sess.run([prediction, accuracy], feed_dict = {X:input_batch, Y:target_batch})\n",
        "\n",
        "predict_word = []\n",
        "for idx,val in enumerate(seq_data):\n",
        "  last_char = char_arr[predict[idx]]\n",
        "  predict_word.append(val[:3]+last_char)\n",
        "\n",
        "print('입력값:', [w[:3]+' ' for w in seq_data])\n",
        "print('예측값:', predict_word)\n",
        "print('정확도:', accuracy_val)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력값: ['abc ', 'wor ', 'woo ', 'dee ', 'div ', 'col ', 'coo ', 'loa ', 'lov ', 'kis ', 'kin ']\n",
            "예측값: ['abcd', 'word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
            "정확도: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p28EMuOFKu4B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}