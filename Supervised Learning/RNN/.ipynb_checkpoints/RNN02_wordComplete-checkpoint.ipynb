{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JeonJeongMin/tensorflow-examples/blob/master/Supervised%20Learning/RNN02_wordComplete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fF-zcMcOK_6k"
   },
   "source": [
    "#Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwzHUt6y4lnr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "char_arr = ['a','b','c','d','e','f','g',\n",
    "            'h','i','j','k','l','m','n',\n",
    "            'o','p','q','r','s','t','u',\n",
    "            'v','w','x','y','z']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GL4k7t2lLHN5"
   },
   "source": [
    "#Make a word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ElYlJ52s6wVO"
   },
   "outputs": [],
   "source": [
    "seq_data = ['abcd','word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
    "def make_batch(seq_data):\n",
    "  input_batch=[]\n",
    "  target_batch=[]\n",
    "  \n",
    "  for seq in seq_data:\n",
    "    input = [num_dic[n] for n in seq[:-1]]\n",
    "    target = num_dic[seq[-1]]\n",
    "    input_batch.append(np.eye(dic_len)[input])#one_hot_encoding\n",
    "    target_batch.append(target)\n",
    "    \n",
    "  return input_batch, target_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxIY0kjYLYEp"
   },
   "source": [
    "#Setting Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_2DsPbTEPuQ"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_hidden =128\n",
    "total_epoch = 50\n",
    "\n",
    "n_step = 3\n",
    "n_input = n_class = dic_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QFMV-lALdXr"
   },
   "source": [
    "#Make a Multi-RNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYF2GyOhFGhQ"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "Y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "cell1 = tf.nn.rnn_cell.LSTMCell(n_hidden)\n",
    "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob = 0.5)\n",
    "cell2 = tf.nn.rnn_cell.LSTMCell(n_hidden)\n",
    "\n",
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1,cell2])\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
    "\n",
    "outputs = tf.transpose(outputs,[1,0,2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.layers.dense(outputs, n_class, activation = None)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                        logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FzKwHXdNLh2R"
   },
   "source": [
    "#Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "colab_type": "code",
    "id": "zb3-suBAGIlU",
    "outputId": "81b473d2-d77b-4850-c2a6-e09f85f068fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Start!\n",
      "Epoch:01 Cost:3.264422\n",
      "Epoch:02 Cost:3.126595\n",
      "Epoch:03 Cost:2.892318\n",
      "Epoch:04 Cost:2.328626\n",
      "Epoch:05 Cost:1.563359\n",
      "Epoch:06 Cost:1.695839\n",
      "Epoch:07 Cost:1.341806\n",
      "Epoch:08 Cost:1.002718\n",
      "Epoch:09 Cost:1.083760\n",
      "Epoch:10 Cost:0.993529\n",
      "Epoch:11 Cost:0.795121\n",
      "Epoch:12 Cost:0.641947\n",
      "Epoch:13 Cost:0.540534\n",
      "Epoch:14 Cost:0.514443\n",
      "Epoch:15 Cost:0.409392\n",
      "Epoch:16 Cost:0.351125\n",
      "Epoch:17 Cost:0.332804\n",
      "Epoch:18 Cost:0.262500\n",
      "Epoch:19 Cost:0.369718\n",
      "Epoch:20 Cost:0.292628\n",
      "Epoch:21 Cost:0.311017\n",
      "Epoch:22 Cost:0.215484\n",
      "Epoch:23 Cost:0.187132\n",
      "Epoch:24 Cost:0.231440\n",
      "Epoch:25 Cost:0.211865\n",
      "Epoch:26 Cost:0.158947\n",
      "Epoch:27 Cost:0.154033\n",
      "Epoch:28 Cost:0.260898\n",
      "Epoch:29 Cost:0.252150\n",
      "Epoch:30 Cost:0.103076\n",
      "Epoch:31 Cost:0.121701\n",
      "Epoch:32 Cost:0.110077\n",
      "Epoch:33 Cost:0.141599\n",
      "Epoch:34 Cost:0.126803\n",
      "Epoch:35 Cost:0.108686\n",
      "Epoch:36 Cost:0.175021\n",
      "Epoch:37 Cost:0.106488\n",
      "Epoch:38 Cost:0.210099\n",
      "Epoch:39 Cost:0.133590\n",
      "Epoch:40 Cost:0.085403\n",
      "Epoch:41 Cost:0.097421\n",
      "Epoch:42 Cost:0.041355\n",
      "Epoch:43 Cost:0.129765\n",
      "Epoch:44 Cost:0.068772\n",
      "Epoch:45 Cost:0.060420\n",
      "Epoch:46 Cost:0.050909\n",
      "Epoch:47 Cost:0.065368\n",
      "Epoch:48 Cost:0.084995\n",
      "Epoch:49 Cost:0.033254\n",
      "Epoch:50 Cost:0.020806\n",
      "Learning Finish!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "print('Learning Start!')\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "  _, cost_val = sess.run([optimizer,cost], feed_dict={X:input_batch, Y:target_batch})\n",
    "  print('Epoch:{:02d}'.format(epoch+1), 'Cost:%3f'%cost_val)\n",
    "  \n",
    "print('Learning Finish!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WS19O95Ljrr"
   },
   "source": [
    "#Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "_X_dQ7GkG6Br",
    "outputId": "24cbb9f2-6604-46b6-81f2-0a141418ccce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력값: ['abc ', 'wor ', 'woo ', 'dee ', 'div ', 'col ', 'coo ', 'loa ', 'lov ', 'kis ', 'kin ']\n",
      "예측값: ['abcd', 'word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
      "정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "prediction = tf.cast(tf.argmax(model,1),tf.int32)\n",
    "prediction_check = tf.equal(prediction,Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_check,tf.float32))\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "predict, accuracy_val = sess.run([prediction, accuracy], feed_dict = {X:input_batch, Y:target_batch})\n",
    "\n",
    "predict_word = []\n",
    "for idx,val in enumerate(seq_data):\n",
    "  last_char = char_arr[predict[idx]]\n",
    "  predict_word.append(val[:3]+last_char)\n",
    "\n",
    "print('입력값:', [w[:3]+' ' for w in seq_data])\n",
    "print('예측값:', predict_word)\n",
    "print('정확도:', accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p28EMuOFKu4B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "RNN02_wordComplete.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
