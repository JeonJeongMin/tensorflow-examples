{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN03_seq2seq.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeonJeongMin/tensorflow-examples/blob/master/Supervised%20Learning/RNN03_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vwAgNL2yCa1U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Import module and Define words"
      ]
    },
    {
      "metadata": {
        "id": "ExXUrcKjNbGs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz단어나무놀이소녀키스사랑싫해세계지속하다가엇너의']\n",
        "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
        "dic_len = len(num_dic)\n",
        "\n",
        "seq_data = [['word','단어'],['wood','나무'],\n",
        "            ['game','놀이'],['girl','소녀'],\n",
        "            ['kiss','키스'],['love','사랑'],\n",
        "            ['hate','싫어'],['world','세계'],\n",
        "            ['keep','지속하다'],['going','가다'],\n",
        "            ['what','무엇'],['your','너의']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xRAIuDYTCqem",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Function"
      ]
    },
    {
      "metadata": {
        "id": "d9MjxTuORZwA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#func - S, E, P 단어뒤에 SEP문자를 붙여 길이가 다양하도록 함\n",
        "def putSEP(word,func):\n",
        "  max_len = 5\n",
        "  n_word=len(word)\n",
        "  word+=func*(max_len-n_word)\n",
        "      \n",
        "  return word\n",
        "\n",
        "#One hot encoding등 인코딩,디코닝,타겟 데이터를 정리한다. \n",
        "def make_batch(seq_data):\n",
        "  input_batch = []\n",
        "  output_batch = []\n",
        "  target_batch = []\n",
        "\n",
        "  for seq in seq_data:\n",
        "    input = [num_dic[n] for n in putSEP(seq[0],'P')]\n",
        "    output = [num_dic[n] for n in ('S' + putSEP(seq[1],'E'))]\n",
        "    target = [num_dic[n] for n in (putSEP(seq[1],'E') + 'E')]\n",
        "\n",
        "    input_batch.append(np.eye(dic_len)[input])\n",
        "    output_batch.append(np.eye(dic_len)[output])\n",
        "    target_batch.append(target)\n",
        "\n",
        "  return input_batch, output_batch, target_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7WTHq8TCyFV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Setting Parameter"
      ]
    },
    {
      "metadata": {
        "id": "X1nT8xhbTI-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "n_hidden = 128\n",
        "total_epoch = 100\n",
        "n_class = n_input = dic_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0LVudpETCzYH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Construct seq2seq Network"
      ]
    },
    {
      "metadata": {
        "id": "GN8Hq2_VTRdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "enc_input = tf.placeholder(tf.float32, [None, None, n_input])\n",
        "dec_input = tf.placeholder(tf.float32, [None, None, n_input])\n",
        "targets = tf.placeholder(tf.int64, [None, None])\n",
        "\n",
        "with tf.variable_scope('encode'):\n",
        "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
        "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
        "\n",
        "    outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, enc_input,\n",
        "                                            dtype=tf.float32)\n",
        "\n",
        "with tf.variable_scope('decode'):\n",
        "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
        "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n",
        "    \n",
        "    outputs, dec_states = tf.nn.dynamic_rnn(dec_cell, dec_input,\n",
        "                                            initial_state=enc_states,\n",
        "                                            dtype=tf.float32)\n",
        "\n",
        "\n",
        "model = tf.layers.dense(outputs, n_class, activation=None)\n",
        "\n",
        "\n",
        "cost = tf.reduce_mean(\n",
        "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                logits=model, labels=targets))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "czVfd9z9C2C3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Learning"
      ]
    },
    {
      "metadata": {
        "id": "__4ODFaxYcEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "28717e34-1563-4b80-f972-2a993f95c6cf"
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "input_batch, output_batch, target_batch = make_batch(seq_data)\n",
        "\n",
        "print('Learning Start!')\n",
        "for epoch in range(total_epoch):\n",
        "  _, cost_val = sess.run([optimizer, cost],\n",
        "                     feed_dict={enc_input:input_batch,\n",
        "                                dec_input:output_batch,\n",
        "                                targets: target_batch})\n",
        "  #print('Epoch:', '%04d' % (epoch + 1),\n",
        "  #       'cost =', '{:.6f}'.format(cost_val))\n",
        "\n",
        "print('Learning Finish!')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning Start!\n",
            "Learning Finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NtB1EOTKC7uq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Test and Result"
      ]
    },
    {
      "metadata": {
        "id": "YxNDR7w1jT6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e9871711-8df6-4d6e-bdbe-a569fa4fa2ac"
      },
      "cell_type": "code",
      "source": [
        "def translate(word):\n",
        "  \n",
        "  word = putSEP(word,'P');\n",
        "  seq_data = [word, 'P'*len(word)]\n",
        "  input_batch, output_batch, target_batch = make_batch([seq_data])\n",
        "  \n",
        "  prediction = tf.argmax(model,2)#[n_output,step,char]\n",
        "  result = sess.run(prediction, feed_dict={enc_input:input_batch,\n",
        "                                           dec_input:output_batch,\n",
        "                                           targets:target_batch})\n",
        "  decoded = [char_arr[i] for i in result[0]]\n",
        "  \n",
        "  end = decoded.index('E')\n",
        "  print(decoded)\n",
        "  translated = ''.join(decoded[:end])\n",
        "  \n",
        "  return translated\n",
        "print(translate('your'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['너', '의', 'E', 'E', 'E', 'E']\n",
            "너의\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}